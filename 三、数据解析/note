聚焦爬虫：爬虫页面中指定的页面内容
    - 编码流程：
        - 指定url
        - 发起请求
        - 获取响应数据  
        - 数据解析
        - 持久化存储

数据解析分类：
    - 正则
    - bs4
    - xpath（***）通用性强

数据集解析原理概述：
    - 解析的局部的文本内容都会在标签之间或者标签对应的属性中进行存储
    - 1、进行指定标签的定位
    - 2、标签或者标签对应的属性中存储的数据值进行提取（解析）






bs4进行数据解析：
    - 数据解析的原理：
        - 1、标签的定位
        - 2、提取标签、标签属性中存储的数据值
    - bs4数据解析的原理；
     - 1、实例化一个BeautSoup对象，并且将页面源码数据加载到该对象中
     - 2、通过调用BeautSoup对象中相关的属性或者方法进行标签定位和数据提取
     - 环境安装：
        - pip install bs4
        - pip install lxml
    - 如何实例化BeautifulSoup对象：
        - form bs4 import BeautifulSoup
        - 对象的实例化：
            - 1、将本地的html文档中的数据加载到该对象中
                fp=open('./test.html','r',encoding='utf-8')
                soup=BeautifulSoup(fp.html)
            - 2、将互联网上获取的页面源码加载到该对象中 
                page_text=request.text
                soup=BeautifulSoup(page_text,'lxml')
        - 提供的用于数据解析的方法和属性
            - soup.tagName:返回的是文档中第一次出现的tagName对应的标签
            - soup.find():
                - find('tagName'):等同于soup.div
                - 属性定位：
                    - soup.find('div',class_/id/attr='song')
            - soup.fing_all('tagName');返回符合要求的所有标签（列表）
        - select:
            - select('某种选择器(id , class ,标签。。。选择器)'),返回的是一个列表。
            - 层级选择器 ：
                - soup.select('.tang>ul>li>a'):>表示的是一个层级
                - soup.select('.tang > ul a'):空格表示的多个层级
        - 获取标签之间的文本数据就：
            - soup.a.text/string/get_text()
            - text/get_text():可以获取某一个标签中所有的文本内容
            - string：只可以获取该标签下面直系的文本内容
        - 获取标签中属性值：
            - soup.a['href']